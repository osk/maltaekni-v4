{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M√°lt√¶kni 2022, verkefni 4\n",
    "\n",
    "B hluti leystur.\n",
    "\n",
    "## a.\n",
    "\n",
    "√ç √æessum hluta finni√∞ √æi√∞ ykkur √æj√°lfa√∞an markara (part-of-speech-tagger).\n",
    "\n",
    "H√∂ldum √°fram me√∞ vinum okkar √≠ hrokum og hleypid√≥mum. F√¶rum √æau samt √∂ll √≠ l√°gstafi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "with open(\"./data/pride-and-prejudice.txt\", \"rb\") as input_file:\n",
    "  pp_raw = input_file.read().decode('utf8')\n",
    "  # Fjarl√¶gja _ utanum or√∞ (sj√° a. ii.); f√¶ra √≠ l√°gstafi\n",
    "  pp = re.sub(r\"\\_(.*)\\_\", r\"\\1\", pp_raw).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. i.\n",
    "\n",
    "Marki√∞ allan textann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. ii.\n",
    "\n",
    "Finni√∞ √∂ll or√∞in √≠ textanum sem hafa fleiri en eitt mark (t.d. getur sleep b√¶√∞i veri√∞ nafnor√∞ (noun) og sagnor√∞ (verb). Skrifi√∞ fall sem skilar √æeim √∂llum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_more_than_one_mark(marks):\n",
    "  \"\"\"\n",
    "  Find word lemmas with more than one mark, returns as list of dict, e.g.:\n",
    "  \"\"\"\n",
    "  found = []\n",
    "  for token in marks:\n",
    "    seen = next((item for item in found if item[\"word\"] == token.lemma_), None)\n",
    "    if seen:\n",
    "      if not token.pos_ in seen[\"tags\"]:\n",
    "        seen[\"tags\"].append(token.pos_)\n",
    "    else:\n",
    "      found.append({ \"word\": token.lemma_, \"tags\": [token.pos_]})\n",
    "  return [item for item in found if len(item[\"tags\"]) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√ç `pos` f√°um vi√∞ ‚ÄûThe simple [UPOS](https://universaldependencies.org/u/pos/) part-of-speech tag‚Äú. Viljum ekki f√° √æa√∞ sem er flokka√∞ √≠ ‚ÄûOther‚Äú:\n",
    "\n",
    "* `PUNCT` punctuation.\n",
    "* `SYM` symbol. A symbol is a word-like entity that differs from ordinary words by form, function, or both.\n",
    "* `X` other. The tag X is used for words that for some reason cannot be assigned a real part-of-speech category.\n",
    "\n",
    "Aukalega s√° √©g a√∞ `_` var a√∞ koma oft fyrir, √æ√° vegna √æess a√∞ √æa√∞ var nota√∞ til a√∞ t√°kna sk√°letrun, t.d. `_Her_`, e√∞a hva√∞?. Fjarl√¶gjum me√∞ regex √≠ inntaki. En sj√°um svo a√∞ √æa√∞ kemur enn√æ√°? Har√∞k√≥√∞um fjarl√¶gingu √° √æv√≠! Af hverju gerist √æetta? Hver er r√©tta lei√∞in til a√∞ d√≠la?\n",
    "S√≠√∞an fara `.` a√∞ koma fyrir seinna √≠ greiningu..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc, pos_skip_list = [], skip_lemmas = [], skip_stops = True):\n",
    "  \"\"\"\n",
    "  \"Clean\" input doc by removing tags, stopwords and specific lemmas.\n",
    "  \"\"\"\n",
    "  return [token for token in doc if not (token.pos_ in pos_skip_list or (skip_stops and token.is_stop) or token.lemma_ in skip_lemmas)]\n",
    "\n",
    "skipped_pos = ['PUNCT', 'SYM', 'X', 'SPACE']\n",
    "skipped_lemmas = ['_', '.']\n",
    "clean = clean_doc(doc, skipped_pos, skipped_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_one_mark = find_more_than_one_mark(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'pride', 'tags': ['NOUN', 'PROPN', 'VERB']},\n",
       " {'word': 'prejudice', 'tags': ['NOUN', 'VERB']},\n",
       " {'word': 'jane', 'tags': ['NOUN', 'PROPN', 'ADJ', 'VERB']},\n",
       " {'word': 'single', 'tags': ['ADJ', 'VERB']},\n",
       " {'word': 'good', 'tags': ['ADJ', 'ADV', 'NOUN', 'PROPN']},\n",
       " {'word': 'want', 'tags': ['NOUN', 'VERB']},\n",
       " {'word': 'little', 'tags': ['ADJ', 'ADV', 'NOUN']},\n",
       " {'word': 'view', 'tags': ['NOUN', 'VERB']},\n",
       " {'word': 'mind', 'tags': ['NOUN', 'VERB']},\n",
       " {'word': 'dear', 'tags': ['ADJ', 'NOUN', 'PROPN', 'VERB']}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_than_one_mark[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. iii.\n",
    "\n",
    "Skrifi√∞ fall sem skilar √æv√≠ or√∞i sem hefur flest mismunandi m√∂rk, √°samt √∂llum m√∂rkunum sem tilheyra √æv√≠. D√¶mi: (minni, [nhen, lkenvm, feve√æ])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_with_most_marks(marks):\n",
    "  longest = 0\n",
    "  longest_words = []\n",
    "  for mark in marks:\n",
    "    current_length = len(mark[\"tags\"])\n",
    "    if current_length == longest:\n",
    "      longest_words.append(mark)\n",
    "    \n",
    "    if current_length > longest:\n",
    "      longest = current_length\n",
    "      longest_words = [mark]\n",
    "\n",
    "  return longest_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'half', 'tags': ['ADV', 'DET', 'ADJ', 'NOUN', 'PRON', 'NUM']}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_with_most_marks(more_than_one_mark)[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. iv.\n",
    "\n",
    "Skili√∞ 10 algengustu p√∂runum √° forminu or√∞/mark og t√≠√∞ni √æeirra (t.d. (hundur, nafnor√∞, 300) √∫r textanum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pair': ('mr', 'PROPN'), 'count': 785},\n",
       " {'pair': ('elizabeth', 'PROPN'), 'count': 621},\n",
       " {'pair': ('say', 'VERB'), 'count': 451},\n",
       " {'pair': ('know', 'VERB'), 'count': 388},\n",
       " {'pair': ('darcy', 'PROPN'), 'count': 369},\n",
       " {'pair': ('mrs', 'PROPN'), 'count': 344},\n",
       " {'pair': ('think', 'VERB'), 'count': 333},\n",
       " {'pair': ('sister', 'NOUN'), 'count': 294},\n",
       " {'pair': ('bingley', 'PROPN'), 'count': 278},\n",
       " {'pair': ('bennet', 'PROPN'), 'count': 256}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_counter = Counter([tuple((token.lemma_, token.pos_)) for token in clean])\n",
    "[{ 'pair': element, 'count': count } for element, count in pair_counter.most_common()][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. v.\n",
    "\n",
    "Skrifi√∞ fall sem skilar √∂llum √ær√≠st√¶√∞um (trigrams) af m√∂rkum √≠ textanum, alveg √≥h√°√∞ √æv√≠ hva√∞a or√∞ fylgja √æeim, og ra√∞ar √æeim eftir √æv√≠ hversu oft √æ√¶r birtast. Formi√∞ √° a√∞ vera [mark1, mark2, mark3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_ngram_tags(doc, n):\n",
    "  just_tags = [item.pos_ for item in doc]\n",
    "  ngrams = []\n",
    "\n",
    "  for index in range(len(just_tags)):\n",
    "    if index + n <= len(just_tags):\n",
    "      ngrams.append(just_tags[index : index + n])\n",
    "\n",
    "  countable = [tuple(item) for item in ngrams]\n",
    "  counter = Counter(countable)\n",
    "\n",
    "  return counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('NOUN', 'VERB', 'NOUN'), 2656),\n",
       " (('NOUN', 'NOUN', 'NOUN'), 2394),\n",
       " (('NOUN', 'NOUN', 'VERB'), 2299),\n",
       " (('VERB', 'NOUN', 'NOUN'), 2250),\n",
       " (('VERB', 'NOUN', 'VERB'), 1938),\n",
       " (('NOUN', 'ADJ', 'NOUN'), 1498),\n",
       " (('NOUN', 'VERB', 'VERB'), 1443),\n",
       " (('VERB', 'VERB', 'NOUN'), 1430),\n",
       " (('ADJ', 'NOUN', 'NOUN'), 1353),\n",
       " (('VERB', 'ADJ', 'NOUN'), 1319)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_tags = ordered_ngram_tags(clean, 3)[:10]\n",
    "\n",
    "top_10_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. v. b√≥nus\n",
    "\n",
    "Finni√∞ allar or√∞arunurnar √∫r textanum sem fylgja √æeirri runu. Ef algengasta marka√ær√≠st√¶√∞an er t.d. [determiner, noun, verb] skili√∞ √æi√∞ √∂llum √ær√≠st√¶√∞unum √≠ textanum sem fylgja √æv√≠ formi, t.a.m. [[a, man, says], [the, woman sees], [an, ape, walks]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_sequence_by_tag_sequence(doc, tag_sequence):\n",
    "  found = []\n",
    "\n",
    "  \"\"\"\n",
    "  track the candidates on the form\n",
    "  (words: [word_1, word_2, ... word_n], index: n-1)\n",
    "  \"\"\"\n",
    "  candidates = []\n",
    "  next_candidates = []\n",
    "\n",
    "  for tag in doc:\n",
    "    current_tag = tag.pos_\n",
    "    current_word = tag.lemma_\n",
    "\n",
    "    # advance any advanceable candiates\n",
    "    for candidate in candidates:\n",
    "      if current_tag == tag_sequence[candidate[\"index\"]]:\n",
    "        candidate[\"words\"].append(current_word)\n",
    "        candidate[\"index\"] = candidate[\"index\"] + 1\n",
    "\n",
    "        # is it complete?\n",
    "        if len(candidate[\"words\"]) == len(tag_sequence):\n",
    "          found.append(candidate[\"words\"])\n",
    "        else:\n",
    "          next_candidates.append(candidate)\n",
    "      else:\n",
    "        pass\n",
    "    \n",
    "    # new candidate?\n",
    "    if current_tag == current_tag:\n",
    "      next_candidates.append({ \"words\": [current_word], \"index\": 0 })\n",
    "\n",
    "    candidates = next_candidates\n",
    "    next_candidates = []\n",
    "  return found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['view', 'man', 'enter'],\n",
       " ['neighbourhood', 'truth', 'fix'],\n",
       " ['fix', 'mind', 'surround'],\n",
       " ['surround', 'family', 'consider'],\n",
       " ['lady', 'day', 'hear'],\n",
       " ['netherfield', 'park', 'let'],\n",
       " ['bennet', 'answer', 'want'],\n",
       " ['tell', 'objection', 'hear'],\n",
       " ['invitation', 'dear', 'know'],\n",
       " ['say', 'netherfield', 'take']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_word_sequence_by_tag_sequence(clean, top_10_tags[0][0])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√Åhugavert! Hva√∞ ef vi√∞ lengjum rununa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('VERB',\n",
       "   'ADJ',\n",
       "   'NOUN',\n",
       "   'VERB',\n",
       "   'NOUN',\n",
       "   'NOUN',\n",
       "   'NOUN',\n",
       "   'NOUN',\n",
       "   'NOUN',\n",
       "   'NOUN',\n",
       "   'NOUN',\n",
       "   'NOUN'),\n",
       "  4)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_ngram_tags(clean, 12)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['feel',\n",
       "  'persuade',\n",
       "  'real',\n",
       "  'confidence',\n",
       "  'subsist',\n",
       "  'disappointment',\n",
       "  'charlotte',\n",
       "  'turn',\n",
       "  'fonder',\n",
       "  'regard',\n",
       "  'sister',\n",
       "  'rectitude']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_word_sequence_by_tag_sequence(clean, ordered_ngram_tags(clean, 12)[0][0])[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ekki miki√∞ √∫r √æessu a√∞ f√°, e√∞a hva√∞? Betra a√∞ halda sig vi√∞ minna N?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. vi.\n",
    "\n",
    "Reyni√∞ a√∞ rugla markarann. L√°ti√∞ hann marka setningar sem √æi√∞ telji√∞ a√∞ g√¶tu rugla√∞ hann. Finni√∞ a.m.k. √ærj√∫ d√¶mi um villur sem hann gerir og √∫tsk√Ωri√∞ hva√∞ √æa√∞ er sem g√¶ti hafa rugla√∞ hann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√ûetta reynir √° m√°lfr√¶√∞i kunn√°ttu m√≠na! N√Ωti m√©r listann a√∞ ofan fyrir or√∞ sem hafa margar myndir, einnig n√Ωtast [Universal POS tags](https://universaldependencies.org/u/pos/) og [Word Type](https://wordtype.org/) vel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dear', 'PROPN'), ('john', 'PROPN'), ('letter', 'NOUN'), ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token.lemma_, token.pos_) for token in nlp(\"Dear john letter.\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H√©r √¶tti `dear` a√∞ vera `ADJ`, ekki `PROPN`, `john` er r√©ttilega `PROPN` en `letter` √¶tti a√∞ vera `NOUN`.\n",
    "√ûar sem √æetta er frasi sem √æarfnast l√¶rd√≥ms er √æetta ekki marka√∞ r√©tt. √Åst√¶√∞a fyrir villu er a√∞ t√∫lka √æetta √≠ heildina sem nafn?\n",
    "\n",
    "Sm√° svindl √æv√≠ ef vi√∞ st√¶kkum setningu √≠ a√∞ innihalda meira samhengi er √æetta flokka√∞ r√©tt üôà."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'DET'),\n",
       " ('dear', 'ADJ'),\n",
       " ('john', 'PROPN'),\n",
       " ('letter', 'NOUN'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token.lemma_, token.pos_) for token in nlp(\"A dear john letter.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Man', 'PROPN'),\n",
       " (',', 'PUNCT'),\n",
       " ('what', 'PRON'),\n",
       " ('a', 'DET'),\n",
       " ('day', 'NOUN'),\n",
       " ('this', 'PRON'),\n",
       " ('have', 'AUX'),\n",
       " ('be', 'AUX'),\n",
       " ('!', 'PUNCT')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token.lemma_, token.pos_) for token in nlp(\"Man, what a day this has been!\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`man` ranglega flokka√∞ sem `PROPN` en √¶tti a√∞ vera `INTJ`‚Äîinterjection‚Äî√æar sem √æa√∞ er nota√∞ sem upphr√≥pun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DET'),\n",
       " ('man', 'NOUN'),\n",
       " ('eat', 'VERB'),\n",
       " (',', 'PUNCT'),\n",
       " ('then', 'ADV'),\n",
       " ('shoot', 'NOUN'),\n",
       " ('and', 'CCONJ'),\n",
       " ('leave', 'NOUN'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token.lemma_, token.pos_) for token in nlp(\"The man eats, then shoots and leaves.\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stoli√∞ fr√° b√≥kinni ‚ÄûEats, Shoots & Leaves‚Äú √æar sem vi√∞ viljum endilega koma √æv√≠ fram a√∞ ma√∞urinn bor√∞i, skj√≥ti og fari s√≠√∞an. `shoots` og `leaves` √¶ttu a√∞ vera `VERB`, ekki `NOUN`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.\n",
    "\n",
    "√ç √æessum hluta finni√∞ √æi√∞ ykkur √æj√°lfa√∞an √æ√°ttara (constituency parser)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. i.\n",
    "\n",
    "√û√°tti√∞ allan textann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notum [Berkeley Neural Parser, `benepar`](https://spacy.io/universe/project/self-attentive-parser)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<benepar.integrations.spacy_plugin.BeneparComponent at 0x13fb30a60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import benepar\n",
    "\n",
    "# S√¶kjum g√∂gn fyrir √æ√°ttarann, keyrum einu sinni\n",
    "# benepar.download('benepar_en3')\n",
    "\n",
    "# Notum st√¶rra m√≥del fyrir ensku\n",
    "nlpx = spacy.load('en_core_web_md')\n",
    "\n",
    "nlpx.add_pipe('benepar', config={'model': 'benepar_en3'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H√©r virka√∞i ekki a√∞ keyra neinn k√≥√∞a gegnum Visual Studio Code, en keyr√∞i √≠ jupyter?\n",
    "\n",
    "`TypeError: Couldn't build proto file into descriptor pool: duplicate file name (sentencepiece_model.proto)`\n",
    "\n",
    "Aukalega ver√∞ur allt mun h√¶gara h√©r.. takm√∂rkum okkur vi√∞ 20√æ or√∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_limited = \" \".join(pp.split(\"\\n\")[:20000])\n",
    "cp_parsed = nlpx(pp_limited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. ii.\n",
    "\n",
    "Skrifi√∞ fall sem skilar √∂llum nafnli√∞um (noun phrases) √≠ textanum og ra√∞ar √æeim eftir √æv√≠ hversu oft √æeir birtast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_noun_phrases(noun_phrases):\n",
    "    counter = Counter([phrase.text for phrase in noun_phrases])\n",
    "    return [{ \"noun_phrase\": element, 'count': count } for element, count in counter.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'noun_phrase': 'i', 'count': 2062},\n",
       " {'noun_phrase': 'she', 'count': 1705},\n",
       " {'noun_phrase': 'it', 'count': 1531},\n",
       " {'noun_phrase': 'you', 'count': 1356},\n",
       " {'noun_phrase': 'he', 'count': 1332},\n",
       " {'noun_phrase': 'her', 'count': 766},\n",
       " {'noun_phrase': 'him', 'count': 761},\n",
       " {'noun_phrase': 'they', 'count': 601},\n",
       " {'noun_phrase': 'elizabeth', 'count': 529},\n",
       " {'noun_phrase': 'which', 'count': 522},\n",
       " {'noun_phrase': 'me', 'count': 445},\n",
       " {'noun_phrase': 'them', 'count': 435},\n",
       " {'noun_phrase': 'what', 'count': 378},\n",
       " {'noun_phrase': 'who', 'count': 285},\n",
       " {'noun_phrase': 'that', 'count': 276},\n",
       " {'noun_phrase': 'we', 'count': 252},\n",
       " {'noun_phrase': 'mr. darcy', 'count': 229},\n",
       " {'noun_phrase': 'jane', 'count': 222},\n",
       " {'noun_phrase': 'herself', 'count': 209},\n",
       " {'noun_phrase': 'nothing', 'count': 171}]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_noun_phrases(cp_parsed.noun_chunks)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. iii.\n",
    "\n",
    "Endurtaki√∞ ii. en s√¶ki√∞ n√∫ sagnli√∞i (verb phrases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H√©r er √©g a√∞eins farinn a√∞ taka fl√Ωtlei√∞ir, n√¶sta kemur a√∞ miklu leiti fr√° [stackoverflow svari](https://stackoverflow.com/questions/47856247/extract-verb-phrases-using-spacy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'verb_phrase': 'said', 'count': 32},\n",
       " {'verb_phrase': 'had', 'count': 25},\n",
       " {'verb_phrase': 'know', 'count': 24},\n",
       " {'verb_phrase': 'have', 'count': 20},\n",
       " {'verb_phrase': 'miss', 'count': 15},\n",
       " {'verb_phrase': 'think', 'count': 14},\n",
       " {'verb_phrase': 'see', 'count': 13},\n",
       " {'verb_phrase': 'do', 'count': 12},\n",
       " {'verb_phrase': 'dance', 'count': 11},\n",
       " {'verb_phrase': 'say', 'count': 10}]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "def parse_verb_phrases(doc):\n",
    "    # Bad function, relies on global state\n",
    "    patterns = [{'POS': 'VERB', 'OP': '?'},\n",
    "               {'POS': 'ADV', 'OP': '*'},\n",
    "               {'POS': 'AUX', 'OP': '*'},\n",
    "               {'POS': 'VERB', 'OP': '+'}]\n",
    "\n",
    "    matcher = Matcher(nlpx.vocab)\n",
    "    matcher.add(\"Verb phrase\", [pattern])\n",
    "\n",
    "    matches = matcher(doc)\n",
    "    spans = [doc[start:end] for _, start, end in matches]\n",
    "    \n",
    "    return spans\n",
    "\n",
    "def ordered_verb_phrases(verb_phrases):\n",
    "    counter = Counter([phrase.text for phrase in verb_phrases])\n",
    "    return [{ \"verb_phrase\": element, 'count': count } for element, count in counter.most_common()]\n",
    "\n",
    "ordered_verb_phrases(parse_verb_phrases(cp_parsed))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. iv.\n",
    "\n",
    "Reyni√∞ a√∞ rugla √æ√°ttarann. L√°ti√∞ hann √æ√°tta setningar sem √æi√∞ telji√∞ a√∞ g√¶tu rugla√∞ hann. Finni√∞ a.m.k. √ærj√∫ d√¶mi um villur sem hann gerir og √∫tsk√Ωri√∞ hva√∞ √æa√∞ er sem g√¶ti hafa rugla√∞ hann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for chunk in nlpx(\"Table that for later\").noun_chunks:\n",
    "    print(chunk)\n",
    "parse_verb_phrases(nlpx(\"Table that for later\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H√©r √¶tti table a√∞ vera flokka√∞ sem s√∂gn en er flokka√∞ sem hvorugt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me\n",
      "you\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Let]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for chunk in nlpx(\"Let me Google that for you\").noun_chunks:\n",
    "    print(chunk)\n",
    "parse_verb_phrases(nlpx(\"Let me Google that for you\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svindl. H√©r √¶tti Google a√∞ vera s√∂gn (og er flokku√∞ sem sl√≠k ef vi√∞ setjum G √≠ l√°gstaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A√∞ finna √æessi d√¶mi var erfi√∞asti parturinn vi√∞ verkefni√∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae2e14ec575573b8be072e4f3a87b89fe042cbcbb9ac3447dde126ec4009b8f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
